{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 8.2 ms (started: 2021-03-25 12:40:03 +00:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from toolz import valmap\n",
    "from typing import Tuple\n",
    "\n",
    "for folder in itertools.chain([Path.cwd()], Path.cwd().parents):\n",
    "    if (folder / 'Pipfile').exists():\n",
    "        os.chdir(folder)\n",
    "        break\n",
    "\n",
    "from notebooks.heart_transplant.dependencies.heart_transplant_data import get_rolling_cv_inputs_cached\n",
    "from notebooks.heart_transplant.dependencies.heart_transplant_functions import get_rolling_cv, \\\n",
    "    remove_missing_columns\n",
    "from notebooks.heart_transplant.dependencies.heart_transplant_pipelines import get_transform, \\\n",
    "    get_xgboost_pipeline, get_random_forest_pipeline\n",
    "\n",
    "from evaluation_functions import get_1_class_y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]2390.7s, 39.8min: Loading get_rolling_cv_inputs...\n",
      "time: 1.63 s (started: 2021-03-25 12:32:21 +00:00)\n"
     ]
    }
   ],
   "source": [
    "_, y, X, dataset_raw, sampling_sets = get_rolling_cv_inputs_cached()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-fdc8b0ce5f72>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclassifier__sample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX_train_weights\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0my_score\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_1_class_y_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m     \u001B[0mroc_auc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mroc_auc_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_score\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m     \u001B[0mresults_all\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'weighted'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmax_year\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mroc_auc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'roc_auc_score' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.5 s (started: 2021-03-25 12:40:05 +00:00)\n"
     ]
    }
   ],
   "source": [
    "for train_set, test_set in sampling_sets:\n",
    "    print('.')\n",
    "    X_train = X.iloc[train_set].assign(tx_year=dataset_raw['tx_year']).sort_values(by='tx_year').drop(columns='tx_year')\n",
    "    y_train = y.loc[X_train.index]\n",
    "\n",
    "    X_train_with_year = X_train.assign(tx_year=dataset_raw['tx_year'])\n",
    "\n",
    "    min_year = X_train_with_year['tx_year'].min()\n",
    "    max_year = X_train_with_year['tx_year'].max()\n",
    "\n",
    "    X_train_weights = [ (individual['tx_year']-min_year) / (max_year-min_year) for _, individual in X_train_with_year.iterrows()]\n",
    "\n",
    "    X_test = X.iloc[test_set]\n",
    "    y_test = y.loc[X_test.index]\n",
    "\n",
    "    model = get_random_forest_pipeline(X, y)\n",
    "\n",
    "    model.fit(X_train, y_train, classifier__sample_weight=X_train_weights)\n",
    "    y_score = get_1_class_y_score(DataFrame(model.predict_proba(X_test)))\n",
    "    roc_auc = roc_auc_score(y_test, y_score)\n",
    "    results_all['weighted'][max_year] = roc_auc\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_score = get_1_class_y_score(DataFrame(model.predict_proba(X_test)))\n",
    "    roc_auc = roc_auc_score(y_test, y_score)\n",
    "    results_all['unweighted'][max_year] = roc_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest ROC AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(dict_to_table_vertical(valmap(lambda i: np.mean(list(i.values())), results_all)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
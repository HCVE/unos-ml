{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 7.69 ms (started: 2021-03-25 12:59:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "for folder in itertools.chain([Path.cwd()], Path.cwd().parents):\n",
    "    if (folder / 'Pipfile').exists():\n",
    "        os.chdir(folder)\n",
    "        break\n",
    "\n",
    "import logging\n",
    "import shelve\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from typing import Mapping, List, Tuple, Iterable, Callable, TypedDict\n",
    "\n",
    "from evaluation_functions import get_classification_metrics, compute_classification_metrics_from_results_with_statistics\n",
    "from formatting import dict_to_table_horizontal, b\n",
    "from functional import pipe\n",
    "from nested_cv import evaluate_method_on_sets, DefaultHyperParameters\n",
    "from notebooks.heart_transplant.dependencies.heart_transplant_data import get_survival_dataset_cached\n",
    "from notebooks.heart_transplant.dependencies.heart_transplant_functions import get_rolling_cv_cached, get_filtered_by_age, AgeGroup, present_table_base, get_survival_y\n",
    "from notebooks.heart_transplant.dependencies.heart_transplant_pipelines import get_xgboost_pipeline, get_cox_ph_pipeline\n",
    "from utils import evaluate_and_assign_if_not_present, mapping_subset\n",
    "from visualisation import list_of_lists_to_html_table, display_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]5656.3s, 94.3min: Loading get_survival_dataset...\n",
      "[Memory]5657.7s, 94.3min: Loading get_survival_dataset...\n",
      "time: 2.83 s (started: 2021-03-25 12:59:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "X_365, y_365, futd_365, death_365, dataset_raw = get_survival_dataset_cached(365)\n",
    "\n",
    "X_90, y_90, futd_90, death_90, _ = get_survival_dataset_cached(90)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "class InputData(TypedDict):\n",
    "    cv: Iterable[Tuple[List[int], ...]] # List of train-test splits (compatible with sklearn)\n",
    "    X: DataFrame # Input data\n",
    "    y: Series # Survival at some time point\n",
    "    futd: Series # Follow-up time (days)\n",
    "    death: Series # Outcome (0 or 1)\n",
    "\n",
    "def get_data(_X: DataFrame, _y: Series, futd: Series, death: Series, _dataset_raw: DataFrame, cv_callback: Callable ) -> InputData:\n",
    "    return InputData(\n",
    "        cv= cv_callback(_X, _dataset_raw),\n",
    "        X= _X,\n",
    "        y= _y,\n",
    "        futd= futd.loc[_X.index],\n",
    "        death= death.loc[_X.index],\n",
    "    )"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.31 ms (started: 2021-03-25 12:59:20 +00:00)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Below is a list of datasets to evaluate the models on. It is a flat structure. You need a separate dataset for 365 and 90 days, since there few individuals are removed\n",
    "- Two types of CV: chronological (rolling) and shuffled 10-fold\n",
    "- Subsets: e.g. 365 survival, $ \\leq 18$, $ > 18$, 90 days"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling notebooks.heart_transplant.dependencies.heart_transplant_functions.get_rolling_cv...\n",
      "get_rolling_cv(        thoracic_dgn gender abo   bmi_calc ebv_igg_cad_don  iabp_tcr  \\\n",
      "2             1002.0      F   O  25.059293               P         0   \n",
      "3             1000.0      M   B  32.140327             NaN         0   \n",
      "5             1007.0      M   A  25.501607               P         0   \n",
      "6             1007.0      M   A  29.023330               P         0   \n",
      "7             1000.0      M   A  21.894900               P         0   \n",
      "...              ...    ...  ..        ...             ...       ...   \n",
      "153202        1007.0      M   A  24.956678               P         0   \n",
      "153203        1000.0      F   A  30.973245             NaN         0   \n",
      "153204        1007.0      F   A  32.269808          ..., n_windows=None, test_size_years=1, minimum_training_years=10, year_stop=2016)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-169f3ee28f62>:18: UserWarning: Persisting input arguments took 5.97s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  return list(get_rolling_cv_cached(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________get_rolling_cv - 6.0s, 0.1min\n",
      "2004 2017 13\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling notebooks.heart_transplant.dependencies.heart_transplant_functions.get_rolling_cv...\n",
      "get_rolling_cv(        thoracic_dgn gender abo   bmi_calc ebv_igg_cad_don  iabp_tcr  \\\n",
      "2             1002.0      F   O  25.059293               P         0   \n",
      "3             1000.0      M   B  32.140327             NaN         0   \n",
      "5             1007.0      M   A  25.501607               P         0   \n",
      "6             1007.0      M   A  29.023330               P         0   \n",
      "7             1000.0      M   A  21.894900               P         0   \n",
      "...              ...    ...  ..        ...             ...       ...   \n",
      "153202        1007.0      M   A  24.956678               P         0   \n",
      "153203        1000.0      F   A  30.973245             NaN         0   \n",
      "153204        1007.0      F   A  32.269808          ..., n_windows=None, test_size_years=1, minimum_training_years=10, year_stop=2016)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-169f3ee28f62>:18: UserWarning: Persisting input arguments took 5.95s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  return list(get_rolling_cv_cached(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________get_rolling_cv - 6.0s, 0.1min\n",
      "2004 2017 13\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling notebooks.heart_transplant.dependencies.heart_transplant_functions.get_rolling_cv...\n",
      "get_rolling_cv(        thoracic_dgn gender abo   bmi_calc ebv_igg_cad_don  iabp_tcr  \\\n",
      "2             1002.0      F   O  25.059293               P         0   \n",
      "3             1000.0      M   B  32.140327             NaN         0   \n",
      "5             1007.0      M   A  25.501607               P         0   \n",
      "6             1007.0      M   A  29.023330               P         0   \n",
      "7             1000.0      M   A  21.894900               P         0   \n",
      "...              ...    ...  ..        ...             ...       ...   \n",
      "153202        1007.0      M   A  24.956678               P         0   \n",
      "153203        1000.0      F   A  30.973245             NaN         0   \n",
      "153204        1007.0      F   A  32.269808          ..., n_windows=None, test_size_years=1, minimum_training_years=10, year_stop=2016)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-169f3ee28f62>:18: UserWarning: Persisting input arguments took 5.35s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  return list(get_rolling_cv_cached(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________get_rolling_cv - 5.3s, 0.1min\n",
      "2004 2017 13\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling notebooks.heart_transplant.dependencies.heart_transplant_functions.get_rolling_cv...\n",
      "get_rolling_cv(        thoracic_dgn gender abo   bmi_calc  iabp_tcr  inotropes_tcr  \\\n",
      "21            1000.0      M   A  21.600000         0              0   \n",
      "31            1207.0      M   O  18.986442         0              0   \n",
      "51            1203.0      F   O  12.500000         0              0   \n",
      "93            1000.0      M   O  24.609375         0              1   \n",
      "98            1203.0      F   A  12.755102         0              1   \n",
      "...              ...    ...  ..        ...       ...            ...   \n",
      "152913        1207.0      M   A  20.328481         0              1   \n",
      "152915        1000.0      F   O  16.982310         0              1   \n",
      "152939        1003.0      F   B  18.169717         0         ..., n_windows=None, test_size_years=1, minimum_training_years=10, year_stop=2016)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-169f3ee28f62>:18: UserWarning: Persisting input arguments took 0.75s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  return list(get_rolling_cv_cached(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________get_rolling_cv - 0.7s, 0.0min\n",
      "2004 2017 13\n",
      "time: 5min 44s (started: 2021-03-25 12:59:20 +00:00)\n"
     ]
    }
   ],
   "source": [
    "data: Mapping[str, InputData] = {\n",
    "    '365_all_rolling': get_data(\n",
    "        X_365,\n",
    "        y_365,\n",
    "        futd_365,\n",
    "        death_365,\n",
    "        dataset_raw,\n",
    "        get_rolling_cv_callback,\n",
    "    ),\n",
    "\n",
    "    '90_all_rolling': get_data(\n",
    "        X_90,\n",
    "        y_90,\n",
    "        futd_90,\n",
    "        death_90,\n",
    "        dataset_raw,\n",
    "        get_rolling_cv_callback,\n",
    "    ),\n",
    "\n",
    "    '365_all_shuffled_10_fold': get_data(\n",
    "        X_365,\n",
    "        y_365,\n",
    "        futd_365,\n",
    "        death_365,\n",
    "        dataset_raw,\n",
    "        get_shuffled_10_fold_callback,\n",
    "    ),\n",
    "\n",
    "    '365_me_18_rolling': get_data(\n",
    "        get_filtered_by_age(AgeGroup.ME_18, X_365),\n",
    "        y_365,\n",
    "        futd_365,\n",
    "        death_365,\n",
    "        dataset_raw,\n",
    "        get_rolling_cv_callback\n",
    "    ),\n",
    "    '365_l_18_rolling': get_data(\n",
    "        get_filtered_by_age(AgeGroup.L_18, X_365).drop(columns=['biopsy_dgn', 'cig_use', 'ebv_igg_cad_don', 'prior_card_surg_trr', 'vessels_50sten']),\n",
    "        y_365,\n",
    "        futd_365,\n",
    "        death_365,\n",
    "        dataset_raw,\n",
    "        get_rolling_cv_callback\n",
    "    ),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root:INFO: 365_ALL_ROLLING_DEFAULT\n",
      "root:DEBUG: Key \"365_all_rolling_default\" not present, executing callback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sitnarf/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sitnarf/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sitnarf/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "root:INFO: Time elapsed: 0:06:39\n",
      "root:INFO: 365_ALL_ROLLING_TUNED\n",
      "root:DEBUG: Key \"365_all_rolling_tuned\" not present, executing callback\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'BayesianOptimization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-0e4f1040476e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     26\u001B[0m     )\n\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m     evaluate_and_assign_if_not_present(\n\u001B[0m\u001B[1;32m     29\u001B[0m         \u001B[0mget_cache\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m         \u001B[0mkey\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msubset_name\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m\"_tuned\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/cardiovascular-risk-app/backend/utils.py\u001B[0m in \u001B[0;36mevaluate_and_assign_if_not_present\u001B[0;34m(data, key, callback, was_not_present_callback, catch_exception, force_execute)\u001B[0m\n\u001B[1;32m    269\u001B[0m             \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 271\u001B[0;31m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    272\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    273\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mCallable\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-22-0e4f1040476e>\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     33\u001B[0m             \u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'X'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m             \u001B[0my_survival\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m             \u001B[0mBayesianOptimization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcox_ph_hyperopt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m             \u001B[0msplits\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'cv'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m             \u001B[0mparallel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'BayesianOptimization' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6min 38s (started: 2021-03-25 13:05:04 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def get_cache():\n",
    "    return shelve.open('cache7')\n",
    "\n",
    "for subset_name, dataset in data.items():\n",
    "\n",
    "    y_survival = pipe(\n",
    "        dataset,\n",
    "        partial(mapping_subset, ('futd', 'death')),\n",
    "        DataFrame,\n",
    "        get_survival_y,\n",
    "    )\n",
    "\n",
    "    evaluate_and_assign_if_not_present(\n",
    "        get_cache,\n",
    "        key=subset_name+\"_default\",\n",
    "        callback=lambda: evaluate_method_on_sets(\n",
    "            lambda: get_cox_ph_pipeline(dataset['X']),   # XGBoost would normally wouldn't take 'death' as y\n",
    "            dataset['X'],\n",
    "            y_survival,\n",
    "            DefaultHyperParameters(),\n",
    "            splits=dataset['cv'],\n",
    "            parallel=True,\n",
    "            n_jobs=len(dataset['cv']),\n",
    "            get_metrics=lambda _, result: get_classification_metrics(dataset['y'], result)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    evaluate_and_assign_if_not_present(\n",
    "        get_cache,\n",
    "        key=subset_name+\"_tuned\",\n",
    "        callback=lambda: evaluate_method_on_sets(\n",
    "            lambda: get_cox_ph_pipeline(dataset['X']),   # XGBoost would normally wouldn't take 'death' as y\n",
    "            dataset['X'],\n",
    "            y_survival,\n",
    "            BayesianOptimization(cox_ph_hyperopt, iterations=10),\n",
    "            splits=dataset['cv'],\n",
    "            parallel=True,\n",
    "            n_jobs=len(dataset['cv']),\n",
    "            get_metrics=lambda _, result: get_classification_metrics(dataset['y'], result)\n",
    "        ),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for subset_name, dataset in data.items():\n",
    "    with get_cache() as cache:\n",
    "        metrics = compute_classification_metrics_from_results_with_statistics(\n",
    "            dataset['y'],\n",
    "            [cache[subset_name]['chosen']['result']],\n",
    "            ignore_warning=True,\n",
    "        )\n",
    "        b(subset_name)\n",
    "        pipe(\n",
    "            metrics,\n",
    "            dict_to_table_horizontal,\n",
    "            list_of_lists_to_html_table,\n",
    "            display_html,\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}